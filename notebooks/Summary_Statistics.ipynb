{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics\n",
    "\n",
    "**CS109a**: Fall 2018\n",
    "\n",
    "**Authors**: Gordon Hew, Wenqin Hu, Blair Leduc\n",
    "\n",
    "**TF**: Ken Arnold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spaCy, a natural language processing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:13:58.353599Z",
     "start_time": "2018-12-13T01:13:54.964613Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (2.0.18)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: regex==2018.01.10 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (2018.1.10)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (1.15.4)\n",
      "Requirement already satisfied: ujson>=1.35 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (6.12.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy) (2.20.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.10.15)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.7)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /Users/blair/.pyenv/versions/3.6.7/lib/python3.6/site-packages/spacy/data/en_core_web_sm\n",
      "\n",
      "    You can now load the model via spacy.load('en_core_web_sm')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import common libraries that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:13:59.013804Z",
     "start_time": "2018-12-13T01:13:58.357083Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('max_seq_items', 4000)\n",
    "pd.set_option('max_rows',20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File locations for input/output of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:13:59.019294Z",
     "start_time": "2018-12-13T01:13:59.015943Z"
    }
   },
   "outputs": [],
   "source": [
    "final_users_df_gz_file = os.path.join('tmp',\n",
    "                                      'users_final_df.pkl.gz')\n",
    "final_tweets_df_gz_file = os.path.join('tmp',\n",
    "                                       'tweets_final_df.pkl.gz')\n",
    "clean_tweets_df_gz_file = os.path.join('tmp', \n",
    "                                       'tweets_clean_df.pkl.gz')\n",
    "users_summary_df_gz_file = os.path.join('data',\n",
    "                                        'users_final_agg_df.pkl.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load User and Tweet Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:06.012665Z",
     "start_time": "2018-12-13T01:13:59.021903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload from binary file\n",
    "users_pkl_df = pd.read_pickle(final_users_df_gz_file, \n",
    "                              compression='gzip')\n",
    "tweets_pkl_df = pd.read_pickle(final_tweets_df_gz_file, \n",
    "                               compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:07.133708Z",
     "start_time": "2018-12-13T01:14:06.016072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy here just incase we corrupt the datasets, we can \n",
    "# start over quickly\n",
    "users_df = users_pkl_df.copy(deep=True)\n",
    "tweets_df = tweets_pkl_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoke test to make sure we loaded things correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:07.148144Z",
     "start_time": "2018-12-13T01:14:07.135675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users: 1000\n",
      "Number of unique users in tweets: 1000\n",
      "User 934576158305345536 has {len(tweets_df[tweets_df['user_id'] == unique_users[0]])}\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of users: {len(users_df)}')\n",
    "unique_users = tweets_df.user_id.unique()\n",
    "print(f'Number of unique users in tweets: {len(unique_users)}')\n",
    "print(f\"User {unique_users[0]} has \" \\\n",
    "      + \"{len(tweets_df[tweets_df['user_id'] == unique_users[0]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the index of users_df to the unique id of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:07.155737Z",
     "start_time": "2018-12-13T01:14:07.150406Z"
    }
   },
   "outputs": [],
   "source": [
    "users_df = users_df.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns to tweets_df that will speed up processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:07.163338Z",
     "start_time": "2018-12-13T01:14:07.157637Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(clean_tweets_df_gz_file).exists():\n",
    "    tweets_df['clean_text'] = tweets_df['text']\\\n",
    "                                .apply(lambda x: ' '.join(\\\n",
    "                                   [t for t in x.split() \n",
    "                                    if (t[0].isalpha() or t[0]=='(')\n",
    "                                        and not t.lower()\\\n",
    "                                                    .startswith('http') \n",
    "                                        and not t == 'RT']))\n",
    "\n",
    "    tweets_df['created_at_hour'] = tweets_df['created_at']\\\n",
    "                                    .apply(lambda x: x[11:13])\\\n",
    "                                    .astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "Preprocess named entities once, here, for use in the rules to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:07.168864Z",
     "start_time": "2018-12-13T01:14:07.165117Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(clean_tweets_df_gz_file).exists():\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    # This column will have an list of named entities\n",
    "    # We can filter on this later\n",
    "    tweets_df['named_entities'] = tweets_df['clean_text']\\\n",
    "        .apply(lambda x: [e.label_ for e in nlp(x).ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save clean and digested tweets_df to save time\n",
    "\n",
    "_Or load the previously saved DataFrame to save time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.845430Z",
     "start_time": "2018-12-13T01:14:07.170879Z"
    }
   },
   "outputs": [],
   "source": [
    "if not Path(clean_tweets_df_gz_file).exists():\n",
    "    tweets_df.to_pickle(clean_tweets_df_gz_file, \n",
    "                        compression='gzip')\n",
    "else:\n",
    "    tweets_df = pd.read_pickle(clean_tweets_df_gz_file, \n",
    "                               compression='gzip')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to process tweets to and add metrics to users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.853909Z",
     "start_time": "2018-12-13T01:14:14.847195Z"
    }
   },
   "outputs": [],
   "source": [
    "class CollectSummaryMetrics:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.columns = []\n",
    "        \n",
    "    def add_column(self, name, processor):\n",
    "        self.columns.append({'name': name, 'func': processor})\n",
    "        \n",
    "    def run_processor(self, processor, s, df):\n",
    "        for i in s.index:\n",
    "            s[i] = processor(df[df['user_id'] == i])\n",
    "        return s\n",
    "    \n",
    "    def run(self, users_df, tweets_df):\n",
    "        df = users_df.copy()\n",
    "        print('Processing:')\n",
    "        unique_users = tweets_df.user_id.unique();\n",
    "        for column in self.columns:\n",
    "            print(f\"Adding column {column['name']}...\")\n",
    "            \n",
    "            df[column['name']] = self.run_processor(column['func'], \n",
    "                        pd.Series(index = unique_users), tweets_df)\n",
    "        print('Done.')\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Summary Metrics\n",
    "* tweets per hour &#x2713;\n",
    "* histogram array for tweets per hour &#x2713;\n",
    "* average number of links per Tweet &#x2713;\n",
    "* average number of contributors per Tweet &#x2717; (no contribs in any tweet)\n",
    "* average tweet status word length per Tweet &#x2713;\n",
    "* average number of hashtags per Tweet &#x2713;\n",
    "* average user mentions per Tweet &#x2713;\n",
    "* average favorite count per Tweet &#x2713;\n",
    "* average media per Tweet &#x2713;\n",
    "* average symbols per Tweet &#x2713;\n",
    "* average retweet count per Tweet &#x2713;\n",
    "* average number of truncated tweets &#x2713;\n",
    "* Total links for each account per Pew reserach Category &#x2713;\n",
    "* Retweet ratio &#x2713;\n",
    "* Natural Language Processing columns (PERSON, NORP, ORG, GPE, PRODUCT, EVENT, LAW, MONEY) &#x2713;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.858037Z",
     "start_time": "2018-12-13T01:14:14.855712Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics = CollectSummaryMetrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.864587Z",
     "start_time": "2018-12-13T01:14:14.859683Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_on_hour(df, hour):\n",
    "    s = df['created_at_hour'].apply(lambda x: x[11:13]).astype(int)\n",
    "    return s[s == hour].count() \n",
    "\n",
    "for hour in range(0,24):\n",
    "    new_metrics.add_column(f'tweets_per_hour_{hour:02}', \n",
    "                           lambda df, hour=hour: \n",
    "                               df['created_at_hour'][\\\n",
    "                                df['created_at_hour'] == hour].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets per hour histogram array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.869905Z",
     "start_time": "2018-12-13T01:14:14.866622Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('tweets_per_hour', \n",
    "                       lambda df: \n",
    "                           np.histogram(df['created_at_hour'], \n",
    "                                        range(0,24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean links per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.875087Z",
     "start_time": "2018-12-13T01:14:14.871687Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_links_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['entities.urls'].apply(lambda x: \n",
    "                                                     len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean number of words per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.880009Z",
     "start_time": "2018-12-13T01:14:14.876948Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_words_per_tweet',\n",
    "                       lambda df: \n",
    "                           df['clean_text'].apply(lambda x: \n",
    "                                                 len(x.split())).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean number of hashtags per Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.885511Z",
     "start_time": "2018-12-13T01:14:14.882392Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_hashtags_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['entities.hashtags'].apply(lambda x: \n",
    "                                                         len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean user mentions per Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.896035Z",
     "start_time": "2018-12-13T01:14:14.892291Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_user_mentions_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['entities.user_mentions']\\\n",
    "                               .apply(lambda x: \n",
    "                                      len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean favorite count per Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.902018Z",
     "start_time": "2018-12-13T01:14:14.898900Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_favourites_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['favorite_count'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean media per Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.907571Z",
     "start_time": "2018-12-13T01:14:14.903751Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_media_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['entities.media'].apply(lambda x: \n",
    "                                                    0 if x != x \n",
    "                                                    else len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean symbols per Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.912572Z",
     "start_time": "2018-12-13T01:14:14.909431Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_user_symbols_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['entities.symbols'].apply(lambda x: \n",
    "                                                    0 if x != x \n",
    "                                                    else len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean retweet count per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.917585Z",
     "start_time": "2018-12-13T01:14:14.914482Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_retweets_per_tweet', \n",
    "                       lambda df: df['retweet_count'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean truncated text per tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.922756Z",
     "start_time": "2018-12-13T01:14:14.919600Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('mean_truncations_per_tweet', \n",
    "                       lambda df: \n",
    "                           df['truncated'].apply(lambda x: \n",
    "                                                 1 if x else 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean number of links per tweet source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.928065Z",
     "start_time": "2018-12-13T01:14:14.924343Z"
    }
   },
   "outputs": [],
   "source": [
    "sources = [c[9:] for c in tweets_df.columns if c.startswith('links_to')]\n",
    "\n",
    "for source in sources:\n",
    "    new_metrics.add_column(f'mean_links_to_{source}', \n",
    "                           lambda df, source=source: \n",
    "                               df[f'links_to_{source}'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retweet ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.933152Z",
     "start_time": "2018-12-13T01:14:14.930127Z"
    }
   },
   "outputs": [],
   "source": [
    "new_metrics.add_column('retweet_ratio', \n",
    "                       lambda df: df['text']\\\n",
    "                           .apply(lambda x: \n",
    "                                  (1 if x.strip().startswith('RT @') \n",
    "                                     else 0)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "\n",
    "We will collect statistics on these named entities:\n",
    "- **PERSON**: People, including fictional.\n",
    "- **NORP**: Nationalities or religious or political groups.\n",
    "- **ORG**: Companies, agencies, institutions, etc.\n",
    "- **GPE**: Countries, cities, states.\n",
    "- **PRODUCT**: Objects, vehicles, foods, etc. (Not services.)\n",
    "- **LAW**: Named documents made into laws.\n",
    "- **MONEY**: Monetary values, including unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:14:14.938540Z",
     "start_time": "2018-12-13T01:14:14.935036Z"
    }
   },
   "outputs": [],
   "source": [
    "named_entities = ['PERSON', 'NORP', 'ORG', 'GPE', \n",
    "                  'PRODUCT', 'LAW', 'MONEY']\n",
    "\n",
    "for entity in named_entities:\n",
    "    new_metrics.add_column(f'mean_ref_to_{entity.lower()}', \n",
    "                          lambda df,entity=entity: df['named_entities']\\\n",
    "                               .apply(lambda x: x.count(entity)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Summary Metrics Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:15:20.538340Z",
     "start_time": "2018-12-13T01:14:14.940520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:\n",
      "Adding column tweets_per_hour_00...\n",
      "Adding column tweets_per_hour_01...\n",
      "Adding column tweets_per_hour_02...\n",
      "Adding column tweets_per_hour_03...\n",
      "Adding column tweets_per_hour_04...\n",
      "Adding column tweets_per_hour_05...\n",
      "Adding column tweets_per_hour_06...\n",
      "Adding column tweets_per_hour_07...\n",
      "Adding column tweets_per_hour_08...\n",
      "Adding column tweets_per_hour_09...\n",
      "Adding column tweets_per_hour_10...\n",
      "Adding column tweets_per_hour_11...\n",
      "Adding column tweets_per_hour_12...\n",
      "Adding column tweets_per_hour_13...\n",
      "Adding column tweets_per_hour_14...\n",
      "Adding column tweets_per_hour_15...\n",
      "Adding column tweets_per_hour_16...\n",
      "Adding column tweets_per_hour_17...\n",
      "Adding column tweets_per_hour_18...\n",
      "Adding column tweets_per_hour_19...\n",
      "Adding column tweets_per_hour_20...\n",
      "Adding column tweets_per_hour_21...\n",
      "Adding column tweets_per_hour_22...\n",
      "Adding column tweets_per_hour_23...\n",
      "Adding column tweets_per_hour...\n",
      "Adding column mean_links_per_tweet...\n",
      "Adding column mean_words_per_tweet...\n",
      "Adding column mean_hashtags_per_tweet...\n",
      "Adding column mean_user_mentions_per_tweet...\n",
      "Adding column mean_favourites_per_tweet...\n",
      "Adding column mean_media_per_tweet...\n",
      "Adding column mean_user_symbols_per_tweet...\n",
      "Adding column mean_retweets_per_tweet...\n",
      "Adding column mean_truncations_per_tweet...\n",
      "Adding column mean_links_to_twitter...\n",
      "Adding column mean_links_to_top_social_media...\n",
      "Adding column mean_links_to_top_digital_media...\n",
      "Adding column mean_links_to_top_news...\n",
      "Adding column mean_links_to_top_products_services...\n",
      "Adding column mean_links_to_top_celebrities...\n",
      "Adding column mean_links_to_top_organizations...\n",
      "Adding column mean_links_to_top_sports...\n",
      "Adding column mean_links_to_top_adult...\n",
      "Adding column retweet_ratio...\n",
      "Adding column mean_ref_to_person...\n",
      "Adding column mean_ref_to_norp...\n",
      "Adding column mean_ref_to_org...\n",
      "Adding column mean_ref_to_gpe...\n",
      "Adding column mean_ref_to_product...\n",
      "Adding column mean_ref_to_law...\n",
      "Adding column mean_ref_to_money...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "users_summary_df = new_metrics.run(users_df, tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoke test to check to see if columns added with correct content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:15:20.576993Z",
     "start_time": "2018-12-13T01:15:20.540598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>created_at</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>description</th>\n",
       "      <th>entities.description.urls</th>\n",
       "      <th>entities.url.urls</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_links_to_top_sports</th>\n",
       "      <th>mean_links_to_top_adult</th>\n",
       "      <th>retweet_ratio</th>\n",
       "      <th>mean_ref_to_person</th>\n",
       "      <th>mean_ref_to_norp</th>\n",
       "      <th>mean_ref_to_org</th>\n",
       "      <th>mean_ref_to_gpe</th>\n",
       "      <th>mean_ref_to_product</th>\n",
       "      <th>mean_ref_to_law</th>\n",
       "      <th>mean_ref_to_money</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934576158305345536</th>\n",
       "      <td>False</td>\n",
       "      <td>Sun Nov 26 00:14:54 +0000 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Unapologetic advocate of common law, constitut...</td>\n",
       "      <td>[{'url': 'https://t.co/oOeCSGuJbs', 'expanded_...</td>\n",
       "      <td>[{'url': 'https://t.co/oOeCSGuJbs', 'expanded_...</td>\n",
       "      <td>101647</td>\n",
       "      <td>False</td>\n",
       "      <td>1063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133965632</th>\n",
       "      <td>False</td>\n",
       "      <td>Fri Apr 03 02:54:56 +0000 2015</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>definitely a real human woman and not three du...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2805</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167730160</th>\n",
       "      <td>False</td>\n",
       "      <td>Wed Apr 15 00:56:50 +0000 2015</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>where i end, you’ll begin.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70639</td>\n",
       "      <td>False</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893957155</th>\n",
       "      <td>False</td>\n",
       "      <td>Sat Oct 20 20:11:16 +0000 2012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>it's Kah-doom • UNC • Nigerian • it’s not by f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/jl4BtTkGyL', 'expanded_...</td>\n",
       "      <td>56239</td>\n",
       "      <td>False</td>\n",
       "      <td>429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540553113</th>\n",
       "      <td>False</td>\n",
       "      <td>Fri Mar 30 02:47:09 +0000 2012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11727</td>\n",
       "      <td>False</td>\n",
       "      <td>454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    contributors_enabled                      created_at  \\\n",
       "id                                                                         \n",
       "934576158305345536                 False  Sun Nov 26 00:14:54 +0000 2017   \n",
       "3133965632                         False  Fri Apr 03 02:54:56 +0000 2015   \n",
       "3167730160                         False  Wed Apr 15 00:56:50 +0000 2015   \n",
       "893957155                          False  Sat Oct 20 20:11:16 +0000 2012   \n",
       "540553113                          False  Fri Mar 30 02:47:09 +0000 2012   \n",
       "\n",
       "                    default_profile  default_profile_image  \\\n",
       "id                                                           \n",
       "934576158305345536             True                  False   \n",
       "3133965632                     True                  False   \n",
       "3167730160                     True                  False   \n",
       "893957155                     False                  False   \n",
       "540553113                     False                  False   \n",
       "\n",
       "                                                          description  \\\n",
       "id                                                                      \n",
       "934576158305345536  Unapologetic advocate of common law, constitut...   \n",
       "3133965632          definitely a real human woman and not three du...   \n",
       "3167730160                                 where i end, you’ll begin.   \n",
       "893957155           it's Kah-doom • UNC • Nigerian • it’s not by f...   \n",
       "540553113                                                         21.   \n",
       "\n",
       "                                            entities.description.urls  \\\n",
       "id                                                                      \n",
       "934576158305345536  [{'url': 'https://t.co/oOeCSGuJbs', 'expanded_...   \n",
       "3133965632                                                         []   \n",
       "3167730160                                                         []   \n",
       "893957155                                                          []   \n",
       "540553113                                                          []   \n",
       "\n",
       "                                                    entities.url.urls  \\\n",
       "id                                                                      \n",
       "934576158305345536  [{'url': 'https://t.co/oOeCSGuJbs', 'expanded_...   \n",
       "3133965632                                                        NaN   \n",
       "3167730160                                                        NaN   \n",
       "893957155           [{'url': 'https://t.co/jl4BtTkGyL', 'expanded_...   \n",
       "540553113                                                         NaN   \n",
       "\n",
       "                    favourites_count  follow_request_sent  followers_count  \\\n",
       "id                                                                           \n",
       "934576158305345536            101647                False             1063   \n",
       "3133965632                      2805                False               55   \n",
       "3167730160                     70639                False              161   \n",
       "893957155                      56239                False              429   \n",
       "540553113                      11727                False              454   \n",
       "\n",
       "                          ...         mean_links_to_top_sports  \\\n",
       "id                        ...                                    \n",
       "934576158305345536        ...                              0.0   \n",
       "3133965632                ...                              0.0   \n",
       "3167730160                ...                              0.0   \n",
       "893957155                 ...                              0.0   \n",
       "540553113                 ...                              0.0   \n",
       "\n",
       "                    mean_links_to_top_adult  retweet_ratio  \\\n",
       "id                                                           \n",
       "934576158305345536                      0.0           0.61   \n",
       "3133965632                              0.0           0.57   \n",
       "3167730160                              0.0           1.00   \n",
       "893957155                               0.0           0.84   \n",
       "540553113                               0.0           0.39   \n",
       "\n",
       "                    mean_ref_to_person mean_ref_to_norp  mean_ref_to_org  \\\n",
       "id                                                                         \n",
       "934576158305345536                0.28             0.05             0.27   \n",
       "3133965632                        0.11             0.01             0.15   \n",
       "3167730160                        0.26             0.03             0.19   \n",
       "893957155                         0.22             0.04             0.15   \n",
       "540553113                         0.09             0.03             0.23   \n",
       "\n",
       "                    mean_ref_to_gpe mean_ref_to_product  mean_ref_to_law  \\\n",
       "id                                                                         \n",
       "934576158305345536             0.07                0.00              0.0   \n",
       "3133965632                     0.02                0.00              0.0   \n",
       "3167730160                     0.19                0.02              0.0   \n",
       "893957155                      0.11                0.01              0.0   \n",
       "540553113                      0.04                0.00              0.0   \n",
       "\n",
       "                   mean_ref_to_money  \n",
       "id                                    \n",
       "934576158305345536              0.00  \n",
       "3133965632                      0.00  \n",
       "3167730160                      0.00  \n",
       "893957155                       0.01  \n",
       "540553113                       0.00  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save updated users' dataframe for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T01:15:20.901039Z",
     "start_time": "2018-12-13T01:15:20.578714Z"
    }
   },
   "outputs": [],
   "source": [
    "users_summary_df.to_pickle(users_summary_df_gz_file, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
